{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Object Detection\n",
        "\n",
        "- Author: Sakthi Santhosh\n",
        "- Created on: 21/08/2022"
      ],
      "metadata": {
        "id": "pmE_vUBFsj0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Modules"
      ],
      "metadata": {
        "id": "9YoIuVnz2VHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cv2 import (\n",
        "    COLOR_BGR2RGB,\n",
        "    VideoCapture,\n",
        "    imwrite,\n",
        "    imread,\n",
        "    cvtColor\n",
        ")\n",
        "from os import path\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "z65nf46osnXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Declarations"
      ],
      "metadata": {
        "id": "HovC55Gusq42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATHS = {\n",
        "    \"capture\": \"./workspace/camera\",\n",
        "    \"testing\": (\n",
        "        \"./workspace/testing\",\n",
        "        \"./workspace/testing/images\",\n",
        "        \"./workspace/testing/annotations\"\n",
        "    ),\n",
        "    \"training\": (\n",
        "        \"./workspace/training\",\n",
        "        \"./workspace/training/images\",\n",
        "        \"./workspace/training/annotations\"\n",
        "    ),\n",
        "    \"export\": (\n",
        "        \"./workspace/export\",\n",
        "        \"./workspace/export/tflite\"\n",
        "    ),\n",
        "    \"label_map\": \"./workspace/label_map.pbtxt\",\n",
        "    \"pretrained_model\": \"./models/pretrained\",\n",
        "    \"custom_model\": \"./models/custom\",\n",
        "    \"tools\": \"./tools/research/object_detection\",\n",
        "    \"output\": \"./workspace/output\",\n",
        "    \"record\": \"./workspace/record\"\n",
        "}\n",
        "\n",
        "CAPTURE_COUNT = 12\n",
        "DETECTION_THRESHOLD = 0.7"
      ],
      "metadata": {
        "id": "jON_BaFzsvBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Label and Label Map"
      ],
      "metadata": {
        "id": "Bw4zxHkLsxXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./objects.txt\", 'r') as file_handle:\n",
        "    LABELS = tuple(map(str.strip, file_handle.readlines()))\n",
        "\n",
        "LABEL_MAP = []\n",
        "for index, label in enumerate(LABELS, start=1):\n",
        "    LABEL_MAP.append({\n",
        "        \"name\": label,\n",
        "        \"id\": index\n",
        "    })"
      ],
      "metadata": {
        "id": "lw0OF86bs0Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Folders"
      ],
      "metadata": {
        "id": "vsLcvxu0s3hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not path.exists(\"./workspace\"):\n",
        "    !mkdir ./workspace/ {PATHS[\"export\"][0]} {PATHS[\"export\"][1]} \\\n",
        "        {PATHS[\"output\"]} {PATHS[\"record\"]}\n",
        "\n",
        "if not path.exists(\"./models\"):\n",
        "    !mkdir ./models/ {PATHS[\"pretrained_model\"]} {PATHS[\"custom_model\"]}\n",
        "\n",
        "if not path.exists(\"./tools\"):\n",
        "    !mkdir ./tools/\n",
        "\n",
        "if not path.exists(PATHS[\"capture\"]):\n",
        "    !mkdir {PATHS[\"capture\"]}\n",
        "\n",
        "if not path.exists(PATHS[\"output\"]):\n",
        "    !mkdir {PATHS[\"output\"]}\n",
        "\n",
        "if not path.exists(PATHS[\"testing\"][0]):\n",
        "    !mkdir {PATHS[\"testing\"][0]} {PATHS[\"testing\"][1]} {PATHS[\"testing\"][2]}\n",
        "\n",
        "if not path.exists(PATHS[\"training\"][0]):\n",
        "    !mkdir {PATHS[\"training\"][0]} {PATHS[\"training\"][1]} {PATHS[\"training\"][2]}\n",
        "\n",
        "for label in LABELS:\n",
        "    folder = path.join(PATHS[\"capture\"], label)\n",
        "    if not path.exists(folder):\n",
        "        !mkdir {folder} {path.join(folder, \"images\")} {path.join(folder, \"annotations\")}"
      ],
      "metadata": {
        "id": "_uMVZ2EPs77w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Capture Images"
      ],
      "metadata": {
        "id": "MkcqI0F1tCeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "camera_handle = VideoCapture(0)\n",
        "for label in LABELS:\n",
        "    print(\"Capturing images for %s.\"%(label))\n",
        "    for counter in range(1, CAPTURE_COUNT + 1):\n",
        "        success, frame = camera_handle.read()\n",
        "        if not success:\n",
        "            print(\"Error: Image capture failed.\")\n",
        "            break\n",
        "        print(\"Saving file %s_image%d.jpg.\"%(label, counter))\n",
        "        imwrite(\n",
        "            path.join(PATHS[\"capture\"], label, \"images\", label + \"_image%d.jpg\"%(counter)),\n",
        "            frame\n",
        "        )\n",
        "        sleep(2)\n",
        "    print()\n",
        "    sleep(5)\n",
        "\n",
        "camera_handle.release()"
      ],
      "metadata": {
        "id": "NAW-YLLBtFHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotating Images\n",
        "\n",
        "- Annotate the images with [Make Sense](https://makesense.ai).\n",
        "- Set the project's name to \"images\".\n",
        "- After downloading the annotations, place them in their respective folders.\n",
        "- Change the ```<path>``` tag to location of the corresponding image."
      ],
      "metadata": {
        "id": "9nwllMhNtGsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy Files for Training and Testing"
      ],
      "metadata": {
        "id": "EpPBcjaRtRpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for label in LABELS:\n",
        "    folder1 = path.join(PATHS[\"capture\"], label, \"images\")\n",
        "    folder2 = path.join(PATHS[\"capture\"], label, \"annotations\")\n",
        "\n",
        "    for counter in range(1, CAPTURE_COUNT + 1, 3):\n",
        "        # Copy images for training.\n",
        "        !cp {path.join(folder1, label + \"_image%d.jpg\"%(counter))} \\\n",
        "            {path.join(folder1, label + \"_image%d.jpg\"%(counter + 1))} \\\n",
        "            {PATHS[\"training\"][1]}\n",
        "        # Copy annotations for training.\n",
        "        !cp {path.join(folder2, label + \"_image%d.xml\"%(counter))} \\\n",
        "            {path.join(folder2, label + \"_image%d.xml\"%(counter + 1))} \\\n",
        "            {PATHS[\"training\"][2]}\n",
        "\n",
        "    for counter in range(3, CAPTURE_COUNT + 1, 3):\n",
        "        # Copy images for testing.\n",
        "        !cp {path.join(folder1, label + \"_image%d.jpg\"%(counter))} \\\n",
        "            {PATHS[\"testing\"][1]}\n",
        "        # Copy annotations for testing.\n",
        "        !cp {path.join(folder2, label + \"_image%d.xml\"%(counter))} \\\n",
        "            {PATHS[\"testing\"][2]}"
      ],
      "metadata": {
        "id": "10BrbcYdtS71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Models and Tools"
      ],
      "metadata": {
        "id": "UjQnjVk1tc8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pretrained model.\n",
        "!wget -O ./models/pretrained/model.tar.gz \\\n",
        "    http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "# Extract the pretrained model.\n",
        "!tar -x -z -f ./models/pretrained/model.tar.gz -C ./models/pretrained/\n",
        "\n",
        "# Clone the GitHub repository.\n",
        "!git clone https://github.com/tensorflow/models ./tools/\n",
        "\n",
        "# Generate python files with protobuf-compiler\n",
        "!cd ./tools/research/ && protoc ./object_detection/protos/*.proto --python_out=./\n",
        "\n",
        "# Install required libraries.\n",
        "!cp ./tools/research/object_detection/packages/tf2/setup.py ./tools/research/ \\\n",
        "    && python3 -m pip install ./tools/research\n",
        "\n",
        "# Verify installation and change directory to root.\n",
        "!python3 ./tools/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "ZtNAAh3OG8BW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Label Map File"
      ],
      "metadata": {
        "id": "_FFMp9VutlsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(PATHS[\"label_map\"], 'w') as file_handle:\n",
        "    for label_map in LABEL_MAP:\n",
        "        file_handle.write(\"item {\\n\")\n",
        "        file_handle.write(\"\\tname: \\\"%s\\\"\\n\"%(label_map[\"name\"]))\n",
        "        file_handle.write(\"\\tid: %d\\n}\\n\"%(label_map[\"id\"]))"
      ],
      "metadata": {
        "id": "RE4mK8nJtka4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tensorflow Records From Images and Annotations"
      ],
      "metadata": {
        "id": "X-nFNhiktpPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate record files for testing.\n",
        "!python3 ./scripts/record.py {PATHS[\"testing\"][0]}/images/ \\\n",
        "    {PATHS[\"testing\"][0]}/annotations/ {PATHS[\"label_map\"]} \\\n",
        "    {PATHS[\"record\"]}/test.record\n",
        "\n",
        "# Generate record files for training.\n",
        "!python3 ./scripts/record.py {PATHS[\"training\"][0]}/images/ \\\n",
        "    {PATHS[\"training\"][0]}/annotations/ {PATHS[\"label_map\"]} \\\n",
        "    {PATHS[\"record\"]}/train.record"
      ],
      "metadata": {
        "id": "BhH-u1aCRFRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy Pipeline File From Pretrained Model to Custom Model"
      ],
      "metadata": {
        "id": "SczoWqITtx1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp {PATHS[\"pretrained_model\"]}/ssd_mobilenet_v2_fpnlite_320x320/pipeline.config \\\n",
        "    {PATHS[\"custom_model\"]}"
      ],
      "metadata": {
        "id": "IZo5g0boTa-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify Config File for Custom Model\n",
        "\n",
        "### Parameters to Change\n",
        "\n",
        "- ```num_classes```: According to number of objects.\n",
        "- ```batch_size```: 2 - 4\n",
        "- ```fine_tune_checkpoint```: ./models/pretrained/ssd_mobilenet_v2_fpnlite_320x320/checkpoint/ckpt-0\n",
        "- ```fine_tune_checkpoint_type```: detection\n",
        "- ```label_map_path```: ./workspace/label_map.pbtxt\n",
        "- ```tf_record_input_reader.input_path```: workspace/record/train.record\n",
        "- ```eval_input_reader[0].label_map_path```: ./workspace/label_map.pbtxt\n",
        "- ```eval_input_reader[0].tf_record_input_reader```: ./workspace/record/test.record\n",
        "- Optionally, one can change the parameter ```total_steps``` to increase/decrease the number of steps to train the model or specify it as a parameter before training."
      ],
      "metadata": {
        "id": "Jwl7R1OZt2-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model (Finally!)"
      ],
      "metadata": {
        "id": "Qvn6i4ONt40Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./tools/research/object_detection/model_main_tf2.py \\\n",
        "    --model_dir={PATHS[\"custom_model\"]} \\\n",
        "    --pipeline_config_path={PATHS[\"custom_model\"]}/pipeline.config \\\n",
        "    --num_train_steps=2000"
      ],
      "metadata": {
        "id": "n-9FsDwSUozI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model (Optional)\n"
      ],
      "metadata": {
        "id": "s21l52JTuBw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./tools/research/object_detection/model_main_tf2.py \\\n",
        "    --model_dir={PATHS[\"custom_model\"]} \\\n",
        "    --pipeline_config_path={PATHS[\"custom_model\"]}/pipeline.config \\\n",
        "    --checkpoint_dir={PATHS[\"custom_model\"]}"
      ],
      "metadata": {
        "id": "znO49B2zU1sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Trained Model From Checkpoint"
      ],
      "metadata": {
        "id": "PJK2iDFIuIZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "from numpy import array, expand_dims, int64\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import (\n",
        "    config_util,\n",
        "    label_map_util,\n",
        "    visualization_utils\n",
        ")\n",
        "import tensorflow\n",
        "\n",
        "# Load pipeline config and build a detection model.\n",
        "configs = config_util.get_configs_from_pipeline_file(\n",
        "    path.join(PATHS[\"custom_model\"], \"pipeline.config\")\n",
        ")\n",
        "detection_model = model_builder.build(model_config=configs[\"model\"], is_training=False)\n",
        "\n",
        "# Restore checkpoint.\n",
        "checkpoint = tensorflow.compat.v2.train.Checkpoint(model=detection_model)\n",
        "checkpoint.restore(path.join(PATHS[\"custom_model\"], \"ckpt-6\")).expect_partial()\n",
        "\n",
        "@tensorflow.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "metadata": {
        "id": "6TYvd7n0uMMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Detector"
      ],
      "metadata": {
        "id": "pCnX9UHyuQbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_image(image_file):\n",
        "    count = 0\n",
        "    image_handle = imread(image_file)\n",
        "    image_array = array(image_handle)\n",
        "    image_expanded = expand_dims(image_array, axis=0)\n",
        "\n",
        "    input_tensor = tensorflow.convert_to_tensor(image_expanded, dtype=tensorflow.float32)\n",
        "    detection = detect_fn(input_tensor)\n",
        "\n",
        "    detection_count = int(detection.pop(\"num_detections\"))\n",
        "    detection = {key: value[0, :detection_count].numpy() for key, value in detection.items()}\n",
        "    detection[\"num_detections\"] = detection_count\n",
        "\n",
        "    detection[\"detection_classes\"] = detection[\"detection_classes\"].astype(int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_array_with_detections = image_array.copy()\n",
        "\n",
        "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_array_with_detections,\n",
        "        detection[\"detection_boxes\"],\n",
        "        detection[\"detection_classes\"] + label_id_offset,\n",
        "        detection[\"detection_scores\"],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=5,\n",
        "        min_score_thresh=DETECTION_THRESHOLD,\n",
        "        line_thickness=20,\n",
        "        agnostic_mode=False\n",
        "    )\n",
        "    pyplot.savefig(path.join(PATHS[\"output\"], path.basename(image_file)))\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATHS[\"label_map\"])"
      ],
      "metadata": {
        "id": "zbY-gfHMuPQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting Objects From Saved Images"
      ],
      "metadata": {
        "id": "sm2HoykMuWOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for label in LABELS:\n",
        "    for counter in range(3, CAPTURE_COUNT + 1, 3):\n",
        "        detect_image(path.join(PATHS[\"testing\"][1], label + \"_image%d.jpg\"%(counter)))"
      ],
      "metadata": {
        "id": "u8j52EwyubeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freezing the Trained Model"
      ],
      "metadata": {
        "id": "3UB0IUQ1ucoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./tools/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={PATHS[\"custom_model\"]}/pipeline.config \\\n",
        "    --trained_checkpoint_dir={PATHS[\"custom_model\"]} \\\n",
        "    --output_directory={PATHS[\"export\"][0]}"
      ],
      "metadata": {
        "id": "TkEXFtxBsapi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion to TFLite"
      ],
      "metadata": {
        "id": "qZwC_HfUugDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 ./tools/research/object_detection/export_tflite_graph_tf2.py \\\n",
        "    --pipeline_config_path={PATHS[\"custom_model\"]}/pipeline.config \\\n",
        "    --trained_checkpoint_dir={PATHS[\"custom_model\"]} \\\n",
        "    --output_directory={PATHS[\"export\"][1]}\n",
        "\n",
        "!tflite_convert --saved_model_dir={PATHS[\"export\"][1]}/saved_model/ \\\n",
        "    --output_file={PATHS[\"export\"][1]}/saved_model/custom.tflite \\\n",
        "    --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor \\\n",
        "    --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1', \\\n",
        "        'TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "    --inference_type=FLOAT --allow_custom_ops"
      ],
      "metadata": {
        "id": "jxja_og9s3sD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}